{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mvkhKbKEtFLw"
   },
   "source": [
    "## Predict Movie Review Sentiment Positive/Negative\n",
    "\n",
    "### Inspiration: https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/\n",
    "\n",
    "### data: www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4Cwdy-3S6yp2",
    "outputId": "0088f2a1-280f-4bf5-a113-a14b6267ae39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LOT8nd6d3F_9"
   },
   "source": [
    "## Keras Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "qvu3CATj3HuH",
    "outputId": "f6301f60-70f8-4dbc-cf0e-fd64aeee442d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_used 4\n",
      "{'the': 2, 'texas': 3, 's': 4, '<unk>': 5}\n",
      "['I live in Texas']\n",
      "[[5, 5, 5, 3]]\n",
      "[[5 5 5 3 0]]\n"
     ]
    }
   ],
   "source": [
    "text = \"Texas is the    second-largest U.S. state, after Alaska, with an area of 268,820 square miles (696,200 km2). \\\n",
    "The name Texas, based on the Caddo word táyshaʼ (/t'ajʃaʔ/) 'friend', was applied, in the spelling Tejas or Texas, \\\n",
    "[17] by the Spanish to the Caddo themselves, specifically the Hasinai Confederacy,[18] the final -s representing the Spanish plural.\"\n",
    "\n",
    "doc1 = [\"Texas is the    second-largest U.S. state, after Alaska, with an area of 268,820 square miles (696,200 km2).\"]\n",
    "doc2 = [\"The name Texas, based on the Caddo word táyshaʼ (/t'ajʃaʔ/) 'friend', was applied, in the spelling Tejas or Texas, \\\n",
    "[17] by the Spanish to the Caddo themselves, specifically the Hasinai Confederacy,[18] the final -s representing the Spanish plural.\"]\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "top_used = 4\n",
    "print(\"top_used\", top_used)\n",
    "\n",
    "# initialize tokenizer\n",
    "tk = Tokenizer(num_words=(top_used), filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token='<unk>')\n",
    "\n",
    "# fit tokenizer\n",
    "tk.fit_on_texts(doc1)\n",
    "tk.fit_on_texts(doc2)\n",
    "\n",
    "## **Key Step to fix Tokenizer**\n",
    "tk.word_index = {e:i for e,i in tk.word_index.items() if i <= top_used} # <= because tokenizer is 1 indexed\n",
    "tk.word_index[tk.oov_token] = top_used + 1\n",
    "\n",
    "\n",
    "sorted_words = {key:value for key, value in sorted(tk.word_index.items(), key=lambda kv: (kv[1], kv[0]))}\n",
    "print(sorted_words)\n",
    "\n",
    "test = [\"I live in Texas\"]\n",
    "encoded = tk.texts_to_sequences(test)\n",
    "print(test)\n",
    "print(encoded)\n",
    "\n",
    "hot_emb = pad_sequences(encoded, maxlen=5, padding='post')\n",
    "print(hot_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C97QbtjT0TlH"
   },
   "outputs": [],
   "source": [
    "\"\"\" CLEAN TEXT FUNCTION \"\"\"\n",
    "\n",
    "def clean_text(text):\n",
    "    import re\n",
    "    from unicodedata import normalize\n",
    "\n",
    "    # normalize unicode\n",
    "    clean = normalize('NFD', text).encode('ascii', 'ignore')\n",
    "    clean = clean.decode('utf-8')\n",
    "\n",
    "    # remove punctuation\n",
    "    number_handler = re.compile(r'(?<=\\d),(?=\\d)')\n",
    "    punct_re = re.compile('[{}]'.format(re.escape('!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-')))\n",
    "\n",
    "    abreviation = re.compile('[^a-zA-Z0-9-_.]')\n",
    "    clean = abreviation.sub(' ', clean)\n",
    "\n",
    "    clean = number_handler.sub('',clean)\n",
    "    clean = punct_re.sub(' ', clean)\n",
    "\n",
    "    # remove any double whitespace\n",
    "    clean = ' '.join(clean.split())\n",
    "\n",
    "    return clean\n",
    "\n",
    "\n",
    "\"\"\" PASS THE FOLDER PATH \"\"\"\n",
    "\n",
    "def parse_folder(path):\n",
    "    import os\n",
    "    import nltk\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    nltk.download('punkt')\n",
    "    text_data = []\n",
    "    files = sorted(os.listdir(path), reverse=True)\n",
    "    for file in files:\n",
    "        with open(path + file, 'r') as f:\n",
    "          # read text file\n",
    "          text = f.read()\n",
    "          # clean text data\n",
    "          text = clean_text(text)\n",
    "          # tokenize text\n",
    "          words = word_tokenize(text)\n",
    "          # append to data\n",
    "          text_data.append(words)\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "C-Ay9_sFy8kK",
    "outputId": "494dea8d-c31c-4927-8cd0-5f62e459527e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/gm0234/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/gm0234/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  1700\n",
      "Test:  300\n"
     ]
    }
   ],
   "source": [
    "path  = \"./review_polarity/txt_sentoken/\"\n",
    "\n",
    "# input data\n",
    "X = []\n",
    "# output data\n",
    "y = []\n",
    "\n",
    "pos_rev = parse_folder(path=path + \"pos/\")\n",
    "neg_rev = parse_folder(path=path + \"neg/\")\n",
    "\n",
    "for rev in pos_rev:\n",
    "    X.append(rev)\n",
    "    y.append(1)\n",
    "\n",
    "for rev in neg_rev:\n",
    "    X.append(rev)\n",
    "    y.append(0)\n",
    "\n",
    "# split data train - test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "print(\"Train: \",len(y_train))\n",
    "print(\"Test: \",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "zV0RAn1qzbcs",
    "outputId": "8eaf3ad3-05df-4026-e364-da82ab417ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1700\n",
      "100 / 1700\n",
      "200 / 1700\n",
      "300 / 1700\n",
      "400 / 1700\n",
      "500 / 1700\n",
      "600 / 1700\n",
      "700 / 1700\n",
      "800 / 1700\n",
      "900 / 1700\n",
      "1000 / 1700\n",
      "1100 / 1700\n",
      "1200 / 1700\n",
      "1300 / 1700\n",
      "1400 / 1700\n",
      "1500 / 1700\n",
      "1600 / 1700\n"
     ]
    }
   ],
   "source": [
    "top_used = 2000\n",
    "\n",
    "# initialize tokenizer\n",
    "tk = Tokenizer(num_words=(top_used), filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token='<unk>')\n",
    "\n",
    "# fit tokenizer\n",
    "for i, review in enumerate(X_train):\n",
    "    tk.fit_on_texts([' '.join(review)])\n",
    "    # have a feedback\n",
    "    if i % 100 == 0:\n",
    "        print(i,'/',len(X_train))\n",
    "\n",
    "## **Key Step to fix Tokenizer**\n",
    "tk.word_index = {e:i for e,i in tk.word_index.items() if i <= top_used} # <= because tokenizer is 1 indexed\n",
    "tk.word_index[tk.oov_token] = top_used + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "EBPc7wNa2C2I",
    "outputId": "7ba51644-be69-4e05-d748-1ece75f12d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 2, 'a': 3, 'and': 4, 'of': 5, 'to': 6, 'is': 7, 'in': 8, 's': 9, 'it': 10, 'that': 11, 'as': 12, 'with': 13, 'for': 14, 'this': 15, 'film': 16, 'his': 17, 'i': 18, 'he': 19, 'but': 20, 'on': 21, 'are': 22, 't': 23, 'be': 24, 'by': 25, 'one': 26, 'not': 27, 'movie': 28, 'an': 29, 'who': 30, 'you': 31, 'at': 32, 'from': 33, 'they': 34, 'have': 35, 'was': 36, 'has': 37, 'her': 38, 'all': 39, 'there': 40, 'like': 41, 'so': 42, 'out': 43, 'about': 44, 'up': 45, 'what': 46, 'more': 47, 'when': 48, 'she': 49, 'or': 50, 'which': 51, 'their': 52, 'can': 53, 'some': 54, 'just': 55, 'if': 56, 'we': 57, 'him': 58, 'into': 59, 'even': 60, 'no': 61, 'only': 62, 'than': 63, 'good': 64, 'time': 65, 'its': 66, 'most': 67, 'will': 68, 'story': 69, 'would': 70, 'been': 71, 'much': 72, 'character': 73, 'also': 74, 'get': 75, 'do': 76, 'other': 77, 'well': 78, 'characters': 79, 'them': 80, 'two': 81, 'very': 82, 'first': 83, 'see': 84, 'after': 85, 'because': 86, 'way': 87, 'make': 88, 'really': 89, 'does': 90, 'off': 91, 'any': 92, 'too': 93, 'films': 94, 'had': 95, 'while': 96, 'how': 97, 'plot': 98, 'life': 99, 'people': 100, 'where': 101, 'over': 102, 'little': 103, 'then': 104, 'could': 105, 'me': 106, 'scene': 107, 'man': 108, 'bad': 109, 'my': 110, 'never': 111, 'don': 112, 'being': 113, 'best': 114, 'these': 115, 'doesn': 116, 'scenes': 117, 'know': 118, 'new': 119, 'director': 120, 'many': 121, 'movies': 122, 'such': 123, 'here': 124, 'action': 125, 'were': 126, 'through': 127, 'great': 128, 're': 129, 'go': 130, 'another': 131, 'love': 132, 'made': 133, 'us': 134, 'back': 135, 'big': 136, 'something': 137, 'end': 138, 'still': 139, 'seems': 140, 'before': 141, 'world': 142, 'work': 143, 'those': 144, 'makes': 145, 'now': 146, 'however': 147, 'though': 148, 'between': 149, 'down': 150, 'every': 151, 'few': 152, 'real': 153, 'better': 154, 'audience': 155, 'seen': 156, 'going': 157, 'take': 158, 'gets': 159, 'around': 160, 'why': 161, 'performance': 162, 'enough': 163, 'isn': 164, 'should': 165, 'both': 166, 'year': 167, 'last': 168, 'same': 169, 'role': 170, 'old': 171, 'your': 172, 'think': 173, 'funny': 174, 'may': 175, 'long': 176, 'things': 177, 'actually': 178, 'years': 179, 'comedy': 180, 've': 181, 'nothing': 182, 'look': 183, 'thing': 184, 'own': 185, 'fact': 186, 'john': 187, 'say': 188, 'right': 189, 'played': 190, 'find': 191, 'come': 192, 'almost': 193, 'cast': 194, 'did': 195, 'ever': 196, 'since': 197, 'script': 198, 'although': 199, 'star': 200, 'plays': 201, 'young': 202, 'comes': 203, 'm': 204, 'three': 205, 'show': 206, 'again': 207, 'original': 208, 'part': 209, 'screen': 210, 'point': 211, 'acting': 212, 'day': 213, 'without': 214, 'effects': 215, 'lot': 216, 'guy': 217, 'takes': 218, 'quite': 219, 'least': 220, 'course': 221, 'each': 222, 'actors': 223, 'minutes': 224, 'goes': 225, 'during': 226, 'himself': 227, 'might': 228, 'family': 229, 'once': 230, 'rather': 231, 'interesting': 232, 'high': 233, 'away': 234, 'must': 235, 'anything': 236, 'far': 237, 'watch': 238, 'place': 239, 'set': 240, 'fun': 241, 'd': 242, 'yet': 243, 'special': 244, 'didn': 245, 'hard': 246, 'making': 247, 'll': 248, 'bit': 249, 'instead': 250, 'job': 251, 'wife': 252, 'woman': 253, 'give': 254, 'want': 255, 'kind': 256, 'trying': 257, 'always': 258, 'american': 259, 'seem': 260, 'home': 261, 'our': 262, 'hollywood': 263, 'half': 264, 'having': 265, 'sense': 266, 'times': 267, 'picture': 268, 'series': 269, 'probably': 270, 'men': 271, 'pretty': 272, 'along': 273, 'becomes': 274, 'become': 275, 'help': 276, 'everything': 277, 'actor': 278, 'sure': 279, 'dialogue': 280, 'money': 281, 'together': 282, 'black': 283, 'gives': 284, 'given': 285, 'looking': 286, 'everyone': 287, 'horror': 288, 'watching': 289, 'whole': 290, 'father': 291, 'feel': 292, 'done': 293, 'sex': 294, 'less': 295, 'girl': 296, 'wants': 297, 'got': 298, 'mind': 299, 'perhaps': 300, 'completely': 301, 'death': 302, 'music': 303, 'performances': 304, 'next': 305, 'especially': 306, 'looks': 307, 'moments': 308, 'evil': 309, '2': 310, 'night': 311, '10': 312, 'james': 313, 'until': 314, 'whose': 315, 'play': 316, 'ending': 317, 'human': 318, 'couple': 319, 'mother': 320, 'anyone': 321, 'different': 322, 'put': 323, 'reason': 324, 'simply': 325, 'rest': 326, 'city': 327, 'let': 328, 'several': 329, 'case': 330, 'michael': 331, 'small': 332, 'someone': 333, 'thought': 334, 'line': 335, 'dead': 336, 'true': 337, 'lost': 338, 'humor': 339, 'town': 340, 'getting': 341, 'shows': 342, 'left': 343, 'second': 344, 'itself': 345, 'found': 346, 'school': 347, 'friend': 348, 'tv': 349, 'written': 350, 'problem': 351, 'based': 352, 'use': 353, 'wrong': 354, 'comic': 355, 'friends': 356, 'soon': 357, 'called': 358, 'war': 359, 'name': 360, 'david': 361, 'begins': 362, 'entire': 363, 'else': 364, 'stars': 365, 'idea': 366, 'either': 367, 'sequence': 368, 'top': 369, 'main': 370, 'head': 371, 'full': 372, 'turns': 373, 'house': 374, 'final': 375, 'hand': 376, 'later': 377, 'boy': 378, 'live': 379, 'alien': 380, 'relationship': 381, 'tries': 382, 'group': 383, 'keep': 384, 'playing': 385, 'believe': 386, 'often': 387, 'named': 388, 'hour': 389, 'person': 390, 'unfortunately': 391, 'under': 392, 'behind': 393, 'certainly': 394, 'book': 395, 'face': 396, 'used': 397, 'finds': 398, 'run': 399, 'son': 400, 'works': 401, 'despite': 402, 'turn': 403, 'finally': 404, 'doing': 405, 'said': 406, 'shot': 407, 'against': 408, 'days': 409, 'kevin': 410, 'joe': 411, 'tell': 412, 'able': 413, 'style': 414, 'summer': 415, 'perfect': 416, 'children': 417, 'lives': 418, 'running': 419, 'maybe': 420, 'side': 421, 'past': 422, 'won': 423, 'nice': 424, 'moment': 425, 'including': 426, 'lines': 427, 'worth': 428, 'writer': 429, 'kids': 430, 'seeing': 431, 'fight': 432, 'directed': 433, 'supposed': 434, 'starts': 435, 'camera': 436, 'need': 437, 'video': 438, 'earth': 439, 'violence': 440, 'team': 441, 'short': 442, 'game': 443, 'early': 444, 'opening': 445, 'major': 446, 'car': 447, 'care': 448, 'mr': 449, 'upon': 450, 'scream': 451, 'daughter': 452, 'start': 453, 'nearly': 454, 'matter': 455, 'worst': 456, 'jack': 457, 'self': 458, 'killer': 459, 'obvious': 460, 'version': 461, 'robert': 462, 'dark': 463, 'others': 464, 'try': 465, 'exactly': 466, 'disney': 467, 'already': 468, 'review': 469, 'four': 470, 'problems': 471, 'wasn': 472, 'deep': 473, 'title': 474, 'throughout': 475, 'close': 476, 'direction': 477, 'example': 478, 'white': 479, 'jackie': 480, 'entertaining': 481, 'five': 482, 'act': 483, 'drama': 484, 'simple': 485, 'beautiful': 486, 'classic': 487, 'fine': 488, 'knows': 489, 'production': 490, 'eyes': 491, 'known': 492, 'heart': 493, 'sequences': 494, 'screenplay': 495, 'boring': 496, 'o': 497, 'level': 498, 'themselves': 499, 'voice': 500, 'truly': 501, 'hit': 502, 'question': 503, 'sometimes': 504, 'stop': 505, 'hero': 506, 'order': 507, 'sort': 508, 'coming': 509, 'room': 510, 'supporting': 511, 'attempt': 512, 'guys': 513, 'stupid': 514, 'jokes': 515, 'novel': 516, 'kill': 517, '1': 518, 'king': 519, 'roles': 520, 'dog': 521, 'ends': 522, 'genre': 523, 'body': 524, 'strong': 525, 'oscar': 526, 'save': 527, 'beginning': 528, 'murder': 529, 'child': 530, 'computer': 531, 'space': 532, 'tom': 533, 'women': 534, 'york': 535, 'paul': 536, 'peter': 537, 'fiction': 538, 'brother': 539, 'tells': 540, 'hope': 541, 'aren': 542, 'happens': 543, 'saw': 544, 'god': 545, 'yes': 546, 'wonder': 547, 'particularly': 548, 'says': 549, 'hours': 550, 'thriller': 551, 'husband': 552, 'lee': 553, 'possible': 554, 'mostly': 555, 'involving': 556, 'smith': 557, 'none': 558, 'quickly': 559, 'fans': 560, 'appears': 561, 'girls': 562, 'meet': 563, 'worse': 564, 'co': 565, 'lead': 566, 'experience': 567, 'note': 568, 'involved': 569, 'manages': 570, 'eventually': 571, 'romantic': 572, 'future': 573, 'ship': 574, 'laugh': 575, 'mean': 576, 'falls': 577, 'career': 578, 'taking': 579, 'alone': 580, 'extremely': 581, 'lack': 582, 'police': 583, 'living': 584, 'ryan': 585, 'piece': 586, 'bring': 587, 'emotional': 588, 'late': 589, 'planet': 590, 'hell': 591, 'material': 592, 'talk': 593, 'sound': 594, 'science': 595, 'fall': 596, 'single': 597, 'laughs': 598, 'easy': 599, 'poor': 600, 'within': 601, 'battle': 602, 'guess': 603, 'feeling': 604, 'dr': 605, 'oh': 606, 'usually': 607, 'word': 608, 'among': 609, 'interest': 610, 'middle': 611, 'attention': 612, 'de': 613, 'sets': 614, 'theater': 615, 'features': 616, 'feature': 617, 'wild': 618, 'chris': 619, 'type': 620, 'result': 621, 'viewer': 622, 'aliens': 623, 'talent': 624, 'power': 625, 'office': 626, 'obviously': 627, 'feels': 628, 'across': 629, 'elements': 630, 'light': 631, 'happy': 632, 'enjoy': 633, 'television': 634, 'happen': 635, 'chance': 636, 'needs': 637, 'cool': 638, 'jones': 639, 'whether': 640, 'important': 641, 'form': 642, 'told': 643, 'recent': 644, 'expect': 645, 'attempts': 646, 'meets': 647, 'stuff': 648, 'call': 649, 'release': 650, 'serious': 651, 'cop': 652, 'apparently': 653, 'killed': 654, 'except': 655, 'entertainment': 656, 'leads': 657, 'tale': 658, 'turned': 659, 'number': 660, 'remember': 661, 'crime': 662, 'george': 663, 'released': 664, 'premise': 665, 'success': 666, 'history': 667, 'change': 668, 'van': 669, 'near': 670, 'surprise': 671, 'parts': 672, 'girlfriend': 673, 'forced': 674, 'working': 675, 'wonderful': 676, 'red': 677, 'score': 678, 'deal': 679, 'words': 680, 'seemed': 681, 'leave': 682, 'easily': 683, 'crew': 684, 'basically': 685, 'america': 686, 'art': 687, 'hilarious': 688, '3': 689, 'brings': 690, 'taken': 691, 'somehow': 692, 'filmmakers': 693, 'mission': 694, 'robin': 695, 'straight': 696, 'cut': 697, 'party': 698, 'talking': 699, 'local': 700, 'williams': 701, 'rock': 702, 'parents': 703, 'impressive': 704, 'giving': 705, 'gone': 706, 'blood': 707, 'business': 708, 'ago': 709, 'am': 710, 'rich': 711, 'popular': 712, 'events': 713, 'surprisingly': 714, 'using': 715, 'read': 716, 'writing': 717, 'credits': 718, 'filled': 719, 'presence': 720, 'wars': 721, 'difficult': 722, 'wouldn': 723, 'budget': 724, 'kid': 725, 'ben': 726, 'decides': 727, 'present': 728, 'runs': 729, 'reality': 730, 'million': 731, 'means': 732, 'die': 733, 'certain': 734, 'personal': 735, 'whom': 736, 'bob': 737, '4': 738, 'fast': 739, 'r': 740, 'flick': 741, 'third': 742, 'age': 743, 'suspense': 744, 'former': 745, 'sequel': 746, 'begin': 747, 'came': 748, 'shots': 749, 'due': 750, 'effective': 751, 'complete': 752, 'went': 753, 'similar': 754, 'follow': 755, 'brothers': 756, 'dramatic': 757, 'anyway': 758, 'william': 759, 'general': 760, 'company': 761, 'quality': 762, 'absolutely': 763, 'starring': 764, 'slow': 765, 'somewhat': 766, 'drug': 767, 'scary': 768, 'actress': 769, 'box': 770, 'strange': 771, 'minute': 772, 'myself': 773, 'water': 774, 'annoying': 775, 'uses': 776, 'b': 777, 'project': 778, 'ways': 779, 'powerful': 780, 'animated': 781, 'sexual': 782, 'leaves': 783, 'message': 784, 'herself': 785, 'familiar': 786, 'mystery': 787, 'jim': 788, 'figure': 789, 'leaving': 790, 'smart': 791, 'harry': 792, 'predictable': 793, 'moving': 794, 'couldn': 795, 'towards': 796, 'huge': 797, 'learn': 798, 'giant': 799, 'situation': 800, 'opens': 801, 'secret': 802, 'following': 803, 'romance': 804, 'clear': 805, 'excellent': 806, 'thinking': 807, 'sam': 808, 'villain': 809, 'amazing': 810, 'motion': 811, 'effect': 812, 'above': 813, 'add': 814, 'low': 815, 'nor': 816, 'felt': 817, 'solid': 818, 'successful': 819, 'unlike': 820, 'clever': 821, 'bunch': 822, 'intelligent': 823, 'ex': 824, 'eye': 825, 'usual': 826, 'nature': 827, 'bill': 828, 'return': 829, 'e': 830, 'definitely': 831, 'cinema': 832, 'married': 833, 'brilliant': 834, 'ones': 835, 'large': 836, 'create': 837, 'private': 838, 'force': 839, 'beyond': 840, 'previous': 841, 'non': 842, 'follows': 843, 'open': 844, 'plan': 845, 'cameron': 846, 'martin': 847, 'richard': 848, 'batman': 849, 'latest': 850, 'law': 851, 'move': 852, 'points': 853, 'musical': 854, 'understand': 855, 'doubt': 856, 'view': 857, 'cold': 858, 'seriously': 859, 'questions': 860, 'potential': 861, 'happened': 862, 'park': 863, 'visual': 864, 'dream': 865, 'l': 866, 'neither': 867, 'class': 868, 'immediately': 869, 'break': 870, 'bruce': 871, 'studio': 872, 'biggest': 873, 'scott': 874, 'stories': 875, 'viewers': 876, 'prison': 877, 'liked': 878, 'saying': 879, 'country': 880, 'inside': 881, 'favorite': 882, 'overall': 883, 'appear': 884, 'modern': 885, 'truth': 886, 'exciting': 887, 'mess': 888, 'gun': 889, 'mark': 890, 'political': 891, 'heard': 892, 'pay': 893, 'otherwise': 894, 'chase': 895, 'created': 896, 'fails': 897, 'west': 898, 'decent': 899, 'silly': 900, 'bond': 901, 'haven': 902, 'realize': 903, 'wanted': 904, 'stay': 905, 'fan': 906, 'likely': 907, 'merely': 908, 'ten': 909, 'six': 910, '5': 911, 'frank': 912, 'dumb': 913, 'took': 914, 'english': 915, 'sweet': 916, 'impossible': 917, 'escape': 918, 'earlier': 919, 'ultimately': 920, 'allen': 921, 'steve': 922, 'seven': 923, 'max': 924, 'mars': 925, 'free': 926, 'rating': 927, 'brought': 928, 'agent': 929, 'air': 930, 'trouble': 931, 'wait': 932, 'audiences': 933, 'government': 934, 'particular': 935, 'various': 936, 'state': 937, 'today': 938, 'ask': 939, 'stand': 940, 'hands': 941, 'wedding': 942, 'society': 943, 'slightly': 944, 'spend': 945, 'effort': 946, 'subject': 947, 'female': 948, 'willis': 949, 'soundtrack': 950, 'enjoyable': 951, 'screenwriter': 952, 'aspect': 953, 'showing': 954, 'purpose': 955, 'army': 956, 'keeps': 957, 'perfectly': 958, 'joke': 959, 'moves': 960, 'key': 961, 'element': 962, 'totally': 963, 'ideas': 964, 'offers': 965, 'british': 966, 'rated': 967, 'sees': 968, 'u': 969, 'teen': 970, 'actual': 971, 'eddie': 972, 'fire': 973, 'waste': 974, 'stone': 975, 'sister': 976, 'brief': 977, 'street': 978, 'titanic': 979, 'members': 980, 'talented': 981, 'situations': 982, 'spent': 983, 'complex': 984, 'expected': 985, 'fear': 986, 'terrible': 987, 'entirely': 988, 'thinks': 989, 'nick': 990, 'cinematography': 991, 'amusing': 992, 'sight': 993, 'disaster': 994, 'list': 995, 'heavy': 996, 'depth': 997, 'cheap': 998, 'simon': 999, '8': 1000, 'suddenly': 1001, 'ridiculous': 1002, 'convincing': 1003, 'steven': 1004, 'subtle': 1005, 'sci': 1006, 'fi': 1007, 'focus': 1008, 'master': 1009, 'mike': 1010, 'gave': 1011, 'tension': 1012, 'typical': 1013, 'sit': 1014, 'dull': 1015, 'woody': 1016, 'control': 1017, 'club': 1018, 'chan': 1019, 'tone': 1020, 'impact': 1021, 'front': 1022, 'song': 1023, 'highly': 1024, 'longer': 1025, 'wrote': 1026, 'memorable': 1027, 'tim': 1028, 'violent': 1029, 'whatever': 1030, 'greatest': 1031, 'fairly': 1032, 'queen': 1033, 'reasons': 1034, 'mary': 1035, 'detective': 1036, 'proves': 1037, 'animation': 1038, 'minor': 1039, 'lots': 1040, 'realistic': 1041, 'ii': 1042, 'constantly': 1043, 'hold': 1044, 'credit': 1045, 'setting': 1046, 'godzilla': 1047, 'hate': 1048, 'sean': 1049, 'college': 1050, 'background': 1051, 'jackson': 1052, 'hear': 1053, 'ability': 1054, 'further': 1055, 'believable': 1056, 'baby': 1057, 'telling': 1058, 'member': 1059, 'meanwhile': 1060, 'spielberg': 1061, 'brown': 1062, 'j': 1063, 'amount': 1064, 'beauty': 1065, 'blue': 1066, 'provide': 1067, 'theme': 1068, 'slowly': 1069, 'double': 1070, 'quick': 1071, 'energy': 1072, 'asks': 1073, 'clearly': 1074, 'chemistry': 1075, 'atmosphere': 1076, 'knew': 1077, 'flat': 1078, 'president': 1079, 'carter': 1080, 'grace': 1081, 'puts': 1082, 'common': 1083, 'recently': 1084, 'ready': 1085, 'island': 1086, 'humans': 1087, 'worked': 1088, 'tough': 1089, 'cute': 1090, 'carry': 1091, 'awful': 1092, 'alive': 1093, 'officer': 1094, 'outside': 1095, 'development': 1096, 'indeed': 1097, 'consider': 1098, 'period': 1099, 'famous': 1100, 'language': 1101, 'event': 1102, 'plenty': 1103, 'somewhere': 1104, 'songs': 1105, 'ground': 1106, 'sounds': 1107, 'lies': 1108, 'possibly': 1109, 'cinematic': 1110, 'seemingly': 1111, 'doctor': 1112, 'directing': 1113, '1998': 1114, 'delivers': 1115, 'partner': 1116, 'tarantino': 1117, 'wasted': 1118, 'provides': 1119, 'student': 1120, 'century': 1121, 'stands': 1122, 'intelligence': 1123, 'thanks': 1124, 'ride': 1125, 'wish': 1126, 'choice': 1127, 'shown': 1128, 'appearance': 1129, 'interested': 1130, 'dreams': 1131, 'miss': 1132, 'subplot': 1133, 'approach': 1134, 'hot': 1135, 'murphy': 1136, 'mention': 1137, 'casting': 1138, 'produced': 1139, 'climax': 1140, 'trip': 1141, 'tarzan': 1142, 'vampire': 1143, 'yourself': 1144, 'contains': 1145, 'decide': 1146, 'thin': 1147, '1997': 1148, 'charm': 1149, 'conclusion': 1150, 'imagine': 1151, 'monster': 1152, 'remains': 1153, 'boys': 1154, 'billy': 1155, 'saving': 1156, 'mysterious': 1157, 'thus': 1158, 'killing': 1159, 'x': 1160, 'cage': 1161, 'french': 1162, 'road': 1163, 'missing': 1164, 'race': 1165, 'forget': 1166, 'green': 1167, 'opportunity': 1168, 'terrific': 1169, 'basic': 1170, 'considering': 1171, 'central': 1172, 'pull': 1173, 'loud': 1174, 'etc': 1175, 'door': 1176, '1999': 1177, 'caught': 1178, 'chinese': 1179, 'cross': 1180, 'julia': 1181, 'okay': 1182, 'average': 1183, 'travolta': 1184, 'waiting': 1185, 'manner': 1186, 'apart': 1187, 'incredibly': 1188, 'catch': 1189, 'lucas': 1190, 'details': 1191, 'laughing': 1192, 'hardly': 1193, 'pace': 1194, 'fox': 1195, 'pictures': 1196, 'boss': 1197, 'cover': 1198, 'machine': 1199, 'trailer': 1200, 'gay': 1201, 'gore': 1202, 'win': 1203, 'leading': 1204, 'male': 1205, 'onto': 1206, 'writers': 1207, 'system': 1208, 'lame': 1209, 'apartment': 1210, 'write': 1211, 'personality': 1212, 'nights': 1213, 'becoming': 1214, 'anderson': 1215, 'trek': 1216, 'building': 1217, 'looked': 1218, 'adds': 1219, 'search': 1220, 'camp': 1221, 'odd': 1222, 'date': 1223, 'flaws': 1224, 'train': 1225, 'truman': 1226, 'normal': 1227, 'carrey': 1228, 'images': 1229, 'forward': 1230, 'occasionally': 1231, 'shoot': 1232, 'touch': 1233, 'blade': 1234, 'victim': 1235, 'directors': 1236, 'mulan': 1237, 'jason': 1238, 'share': 1239, 'equally': 1240, 'jean': 1241, 'powers': 1242, 'witch': 1243, 'producer': 1244, 'led': 1245, 'christopher': 1246, 'enjoyed': 1247, 'store': 1248, 'pulp': 1249, 'social': 1250, 'sad': 1251, 'innocent': 1252, 'hong': 1253, 'species': 1254, 'image': 1255, 'teacher': 1256, 'discovers': 1257, 'douglas': 1258, 'attack': 1259, 'edge': 1260, 'adventure': 1261, 'sent': 1262, 'aside': 1263, 'jay': 1264, 'leader': 1265, 'learns': 1266, 'adult': 1267, 'phone': 1268, 'include': 1269, 'storyline': 1270, '90': 1271, 'menace': 1272, 'matthew': 1273, 'arnold': 1274, 'answer': 1275, 'critics': 1276, 'bizarre': 1277, 'dance': 1278, 'lawyer': 1279, 'concept': 1280, 'news': 1281, 'older': 1282, 'elizabeth': 1283, 'track': 1284, 'younger': 1285, 'literally': 1286, 'desperate': 1287, 'culture': 1288, 'twenty': 1289, 'rescue': 1290, 'introduced': 1291, 'jennifer': 1292, 'generally': 1293, 'singer': 1294, 'la': 1295, 'kiss': 1296, 'drive': 1297, 'states': 1298, 'includes': 1299, 'dies': 1300, 'food': 1301, 'charming': 1302, 'prove': 1303, 'months': 1304, 'discover': 1305, 'rate': 1306, 'changes': 1307, 'admit': 1308, 'thrown': 1309, 'hill': 1310, 'alan': 1311, 'latter': 1312, 'surprised': 1313, 'returns': 1314, 'pop': 1315, 'standard': 1316, 'mouth': 1317, 'jerry': 1318, 'disturbing': 1319, 'hair': 1320, 'devil': 1321, 'filmed': 1322, 'addition': 1323, 'recommend': 1324, 'walk': 1325, 'c': 1326, 'twice': 1327, 'detail': 1328, 'toward': 1329, 'flying': 1330, 'public': 1331, 'fresh': 1332, 'plane': 1333, 'wise': 1334, 'fellow': 1335, 'gags': 1336, 'woo': 1337, 'nicely': 1338, 'creates': 1339, 'intended': 1340, 'needed': 1341, 'meaning': 1342, 'crazy': 1343, 'fashion': 1344, 'forces': 1345, 'blair': 1346, 'patrick': 1347, 'terms': 1348, 'deserves': 1349, 'twists': 1350, 'vegas': 1351, 'jr': 1352, 'apparent': 1353, 'hasn': 1354, 'exception': 1355, 'epic': 1356, 'russell': 1357, 'ass': 1358, 'sadly': 1359, 'fighting': 1360, '7': 1361, 'witty': 1362, 'weird': 1363, 'julie': 1364, 'numerous': 1365, 'faces': 1366, '000': 1367, 'buy': 1368, 'became': 1369, 'rising': 1370, '20': 1371, 'pieces': 1372, 'likes': 1373, 'unique': 1374, 'accident': 1375, 'limited': 1376, 'pathetic': 1377, 'information': 1378, 'fair': 1379, 'barely': 1380, 'decided': 1381, 'offer': 1382, 'throw': 1383, 'speak': 1384, 'developed': 1385, 'presented': 1386, 'explain': 1387, 'rules': 1388, 'rarely': 1389, 'pointless': 1390, 'roger': 1391, 'crap': 1392, 'vampires': 1393, 'legend': 1394, 'fully': 1395, 'horrible': 1396, 'brain': 1397, 'campbell': 1398, 'land': 1399, 'relief': 1400, 'silent': 1401, 'pick': 1402, 'nowhere': 1403, 'debut': 1404, 'issues': 1405, 'formula': 1406, 'superior': 1407, 'kate': 1408, 'filmmaking': 1409, 'twist': 1410, 'spends': 1411, 'jeff': 1412, 'band': 1413, 'calls': 1414, 'surprising': 1415, 'speaking': 1416, 'soldiers': 1417, 'confusing': 1418, 'contact': 1419, 'fbi': 1420, 'process': 1421, 'comedies': 1422, 'wide': 1423, 'accent': 1424, 'winning': 1425, 'dennis': 1426, 'teenage': 1427, 'appeal': 1428, 'involves': 1429, 'footage': 1430, 'damme': 1431, 'tried': 1432, 'charles': 1433, 'boyfriend': 1434, 'angels': 1435, 'hanks': 1436, 'stephen': 1437, 'considered': 1438, 'mood': 1439, 'cartoon': 1440, 'owner': 1441, 'danny': 1442, 'woods': 1443, 'heads': 1444, 'loves': 1445, 'pair': 1446, 'week': 1447, 'heroes': 1448, 'gang': 1449, 'floor': 1450, 'military': 1451, 'length': 1452, 'kept': 1453, 'sitting': 1454, 'opinion': 1455, 'stage': 1456, 'shakespeare': 1457, 'remake': 1458, 'creepy': 1459, 'emotions': 1460, 'episode': 1461, 'asked': 1462, 'talents': 1463, 'emotion': 1464, 'attitude': 1465, 'task': 1466, 'pain': 1467, 'editing': 1468, 'angry': 1469, 'born': 1470, 'princess': 1471, 'ok': 1472, 'genuine': 1473, 'appropriate': 1474, 'pure': 1475, 'shame': 1476, 'places': 1477, 'incredible': 1478, 'bright': 1479, 'deliver': 1480, 'field': 1481, 'rob': 1482, 'dimensional': 1483, 'plans': 1484, 'avoid': 1485, 'captain': 1486, 'confused': 1487, 'weak': 1488, 'loved': 1489, 'spirit': 1490, 'allows': 1491, 'suppose': 1492, 'please': 1493, 'fascinating': 1494, 'mrs': 1495, 'christmas': 1496, 'feelings': 1497, 'ice': 1498, 'academy': 1499, 'affair': 1500, 'lose': 1501, 'necessary': 1502, 'holds': 1503, 'humorous': 1504, 'fantasy': 1505, 'natural': 1506, 'masterpiece': 1507, 'hits': 1508, 'poorly': 1509, 'kong': 1510, 'journey': 1511, 'creating': 1512, 'naked': 1513, 'slasher': 1514, 'urban': 1515, 'cliches': 1516, 'industry': 1517, 'flynt': 1518, 'spice': 1519, 'apes': 1520, 'patch': 1521, 'charlie': 1522, 'inspired': 1523, 'award': 1524, 'cameo': 1525, 'wall': 1526, 'unless': 1527, 'criminal': 1528, 'rare': 1529, 'pass': 1530, 'gibson': 1531, 'meant': 1532, 'virtually': 1533, 'baldwin': 1534, 'revenge': 1535, 'cause': 1536, 'relationships': 1537, 'lover': 1538, 'toy': 1539, 'zero': 1540, 'fat': 1541, 'names': 1542, 'damn': 1543, 'henry': 1544, 'sub': 1545, 'alex': 1546, 'satire': 1547, 'lacks': 1548, 'impression': 1549, 'suspect': 1550, 'stuck': 1551, 'na': 1552, 'added': 1553, 'theaters': 1554, 'rocky': 1555, 'sign': 1556, 'adaptation': 1557, 'target': 1558, 'magic': 1559, 'artist': 1560, 'continues': 1561, 'phantom': 1562, 'protagonist': 1563, 'dude': 1564, 'reach': 1565, 'rush': 1566, 'tommy': 1567, 'nobody': 1568, 'thomas': 1569, 'graphic': 1570, 'blame': 1571, 'marriage': 1572, 'grand': 1573, 'shallow': 1574, 'creature': 1575, 'station': 1576, 'soul': 1577, 'generated': 1578, 'appealing': 1579, 'dad': 1580, 'cruise': 1581, 'failed': 1582, 'loving': 1583, 'price': 1584, 'affleck': 1585, 'roberts': 1586, 'expectations': 1587, 'mad': 1588, 'gon': 1589, 'dvd': 1590, 'files': 1591, 'speech': 1592, 'dollars': 1593, 'step': 1594, 'count': 1595, 'results': 1596, 'drugs': 1597, 'touching': 1598, 'keeping': 1599, 'intriguing': 1600, 'speed': 1601, 'parody': 1602, 'humanity': 1603, 'respect': 1604, 'disappointing': 1605, 'product': 1606, 'safe': 1607, 'sick': 1608, 'grant': 1609, 'technical': 1610, 'wit': 1611, 'therefore': 1612, 'constant': 1613, 'decision': 1614, 'reviews': 1615, 'generation': 1616, 'device': 1617, 'rent': 1618, 'total': 1619, 'bland': 1620, 'superb': 1621, 'dying': 1622, 'drawn': 1623, 'bottom': 1624, 'professional': 1625, 'plain': 1626, 'adults': 1627, 'fate': 1628, 'realized': 1629, 'appreciate': 1630, 'cash': 1631, 'ford': 1632, 'matt': 1633, 'hoping': 1634, 'guns': 1635, 'moral': 1636, 'jane': 1637, 'troopers': 1638, 'mentioned': 1639, 'bored': 1640, 'anti': 1641, 'ghost': 1642, 'carpenter': 1643, 'sympathetic': 1644, 'feet': 1645, 'worthy': 1646, 'era': 1647, 'spawn': 1648, 'teenagers': 1649, 'themes': 1650, 'color': 1651, 'johnny': 1652, 'hotel': 1653, 'exist': 1654, 'fare': 1655, 'unfunny': 1656, 'edward': 1657, 'smile': 1658, 'mix': 1659, 'cops': 1660, 'g': 1661, 'match': 1662, 'post': 1663, 'trust': 1664, 'utterly': 1665, '13': 1666, 'comedic': 1667, 'hospital': 1668, 'available': 1669, 'shock': 1670, 'opposite': 1671, 'helps': 1672, 'compelling': 1673, 'presents': 1674, 'gold': 1675, 'boat': 1676, 'started': 1677, 'producers': 1678, 'notice': 1679, 'intense': 1680, 'chosen': 1681, 'join': 1682, 'united': 1683, 'compared': 1684, 'manage': 1685, 'flicks': 1686, 'eight': 1687, 'physical': 1688, 'rose': 1689, 'bus': 1690, 'destroy': 1691, 'radio': 1692, 'larry': 1693, 'expecting': 1694, 'moore': 1695, 'tony': 1696, 'send': 1697, 'turning': 1698, 'helen': 1699, 'featuring': 1700, 'dangerous': 1701, 'ed': 1702, 'died': 1703, 'survive': 1704, 'cult': 1705, 'actions': 1706, 'directly': 1707, 'spectacular': 1708, 'difference': 1709, 'finale': 1710, 'scientist': 1711, 'plus': 1712, 'south': 1713, 'lady': 1714, 'loses': 1715, 'managed': 1716, 'pg': 1717, 'documentary': 1718, 'supposedly': 1719, 'players': 1720, 'williamson': 1721, 'portrayal': 1722, 'honest': 1723, 'buddy': 1724, 'allow': 1725, 'crash': 1726, 'annie': 1727, 'matters': 1728, 'fail': 1729, 'board': 1730, 'welcome': 1731, 'adams': 1732, 'succeeds': 1733, 'horse': 1734, 'driver': 1735, 'shooting': 1736, 'winner': 1737, 'crowd': 1738, 'tired': 1739, 'identity': 1740, 'ray': 1741, 'attractive': 1742, 'wonderfully': 1743, 'visuals': 1744, 'engaging': 1745, 'kelly': 1746, 'heaven': 1747, 'professor': 1748, 'nasty': 1749, 'forever': 1750, 'media': 1751, 'fake': 1752, 'goofy': 1753, 'badly': 1754, 'burton': 1755, 'design': 1756, '30': 1757, 'humour': 1758, 'yeah': 1759, 'amy': 1760, 'changed': 1761, 'viewing': 1762, 'books': 1763, 'frightening': 1764, 'washington': 1765, 'fantastic': 1766, 'jedi': 1767, 'austin': 1768, 'stuart': 1769, 'watched': 1770, 'porn': 1771, 'cares': 1772, 'determined': 1773, 'wayne': 1774, 'broken': 1775, 'students': 1776, 'falling': 1777, 'filmmaker': 1778, 'kills': 1779, 'desire': 1780, 'excuse': 1781, 'arts': 1782, 'starship': 1783, 'promise': 1784, 'walking': 1785, 'super': 1786, 'willing': 1787, 'ted': 1788, 'overly': 1789, 'driven': 1790, 'strength': 1791, 'test': 1792, 'liners': 1793, 'nuclear': 1794, 'ms': 1795, 'brooks': 1796, 'conflict': 1797, 'press': 1798, 'driving': 1799, 'al': 1800, 'believes': 1801, 'singing': 1802, 'boogie': 1803, 'figures': 1804, 'serve': 1805, 'aspects': 1806, 'deals': 1807, 'shouldn': 1808, 'slapstick': 1809, 'stunning': 1810, 'technology': 1811, 'check': 1812, 'visually': 1813, 'armageddon': 1814, 'taylor': 1815, 'hunt': 1816, 'finding': 1817, 'catherine': 1818, 'genius': 1819, 'nudity': 1820, 'ultimate': 1821, 'sidney': 1822, 'beach': 1823, 'hurt': 1824, 'characterization': 1825, 'pleasure': 1826, 'mob': 1827, 'imagination': 1828, 'frame': 1829, 'began': 1830, 'breaks': 1831, 'fault': 1832, 'provided': 1833, 'portrayed': 1834, 'scale': 1835, 'narrative': 1836, 'grows': 1837, 'bloody': 1838, 'model': 1839, '1996': 1840, '100': 1841, 'lord': 1842, 'gangster': 1843, 'strike': 1844, 'guilty': 1845, 'sheer': 1846, 'reveal': 1847, 'hopes': 1848, 'joan': 1849, 'extra': 1850, 'standing': 1851, 'steal': 1852, 'japanese': 1853, 'individual': 1854, 'routine': 1855, 'grow': 1856, 'quiet': 1857, 'accept': 1858, 'content': 1859, 'offensive': 1860, 'failure': 1861, 'funniest': 1862, 'direct': 1863, 'sorry': 1864, 'hip': 1865, 'judge': 1866, 'reading': 1867, '9': 1868, 'paced': 1869, 'hopkins': 1870, 'sexy': 1871, 'build': 1872, 'cheesy': 1873, 'folks': 1874, 'martial': 1875, 'taste': 1876, 'realizes': 1877, 'likable': 1878, 'guard': 1879, 'gary': 1880, 'meeting': 1881, 'fly': 1882, 'seagal': 1883, 'current': 1884, 'ill': 1885, 'court': 1886, 'shrek': 1887, 'everybody': 1888, 'explained': 1889, 'decade': 1890, 'thirty': 1891, 'miller': 1892, 'built': 1893, 'cell': 1894, 'emotionally': 1895, 'mediocre': 1896, 'clich': 1897, 'cinematographer': 1898, 'security': 1899, 'brian': 1900, 'struggle': 1901, 'assistant': 1902, 'logic': 1903, 'memory': 1904, 'schwarzenegger': 1905, 'wood': 1906, 'snake': 1907, 'travel': 1908, 'goal': 1909, 'inevitable': 1910, 'hidden': 1911, 'hearted': 1912, 'draw': 1913, 'joel': 1914, 'outstanding': 1915, 'saved': 1916, 'wan': 1917, 'pacing': 1918, 'stock': 1919, 'ended': 1920, 'oliver': 1921, 'streets': 1922, 'fights': 1923, 'surface': 1924, 'clean': 1925, 'london': 1926, 'victims': 1927, 'crystal': 1928, 'ups': 1929, 'substance': 1930, 'chief': 1931, 'position': 1932, 'fill': 1933, 'bar': 1934, 'ahead': 1935, 'anthony': 1936, 'season': 1937, 'window': 1938, 'contrived': 1939, 'matrix': 1940, 'haunting': 1941, 'jimmy': 1942, 'visit': 1943, 'sarah': 1944, 'dealing': 1945, 'instance': 1946, 'serial': 1947, 'lets': 1948, 'holes': 1949, 'myers': 1950, 'freeman': 1951, 'seat': 1952, 'lynch': 1953, 'sandler': 1954, '6': 1955, 'screenwriters': 1956, 'talks': 1957, 'eve': 1958, 'core': 1959, 'fit': 1960, 'besides': 1961, 'jump': 1962, 'forgotten': 1963, 'lucky': 1964, 'breaking': 1965, 'headed': 1966, 'center': 1967, 'weren': 1968, 'numbers': 1969, 'cliche': 1970, 'thankfully': 1971, 'sea': 1972, 'acts': 1973, 'beloved': 1974, 'enter': 1975, 'mistake': 1976, 'ugly': 1977, 'critic': 1978, 'frequently': 1979, 'acted': 1980, 'missed': 1981, 'mental': 1982, 'seconds': 1983, 'courtroom': 1984, 'soldier': 1985, 'value': 1986, 'pie': 1987, 'included': 1988, 'placed': 1989, 'treat': 1990, 'player': 1991, 'cliched': 1992, 'jail': 1993, 'originally': 1994, 'bigger': 1995, 'suspects': 1996, 'worker': 1997, 'creative': 1998, 'lacking': 1999, 'thoroughly': 2000, '<unk>': 2001}\n"
     ]
    }
   ],
   "source": [
    "sorted_words = {key:value for key, value in sorted(tk.word_index.items(), key=lambda kv: (kv[1], kv[0]))}\n",
    "print(sorted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-O_lT6PY_TEt",
    "outputId": "3d24483a-2109-45ee-99ed-7013e710251e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length Review:  2462\n",
      "Vocabulary size:  2000\n"
     ]
    }
   ],
   "source": [
    "# sequence encode\n",
    "X_train = tk.texts_to_sequences(X_train)\n",
    "X_test = tk.texts_to_sequences(X_test)\n",
    "\n",
    "# pad sequences\n",
    "max_length = max([len(s) for s in X_train])\n",
    "print(\"Max Length Review: \",max_length)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding='post')\n",
    "\n",
    "# define vocabulary size (largest integer value)\n",
    "vocab_size = len(tk.word_index)\n",
    "print(\"Vocabulary size: \",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "IiabpxI5AIpz",
    "outputId": "46b2fd2a-6b63-4398-fe86-c26af2ac657b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2462, 100)         200200    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2455, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1227, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 39264)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                392650    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 618,493\n",
      "Trainable params: 618,493\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+2, 100, input_length=max_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "mOj6hU77AKCx",
    "outputId": "7a65c51f-88e6-4865-8152-5455fdf75030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1700/1700 [==============================] - 10s 6ms/step - loss: 0.6946 - acc: 0.5265\n",
      "Epoch 2/2\n",
      "1700/1700 [==============================] - 10s 6ms/step - loss: 0.6548 - acc: 0.6388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aab718b2cc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network - try 10 epochs\n",
    "model.fit(X_train, y_train, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pM37AT73FmVr",
    "outputId": "ac730d6e-1627-4bc9-d62e-8fb68c2ec11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 66.000000\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "movie_review_sentiment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
